"""
ğŸ§© PSYCHOSYMULACJA WIELOAGENTOWA (Multi-Agent Psychosimulation)
==============================================================

Asystent tworzy w tle â€wewnÄ™trzne wersje siebie" o rÃ³Å¼nych rolach 
(Analityk, TwÃ³rca, Krytyk, Filozof). KaÅ¼dy agent generuje warianty odpowiedzi, 
a gÅ‚Ã³wny â€ego" wybiera najlepszÄ…. Efekt: kreatywnoÅ›Ä‡ + kontrola jakoÅ›ci + gÅ‚Ä™bia.

Autor: Zaawansowany System Kognitywny MRD  
Data: 15 paÅºdziernika 2025
"""

import asyncio
import json
import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, asdict
from enum import Enum
import random
import hashlib

from .config import *
from .llm import get_llm_client
from .memory import get_memory_manager
from .hierarchical_memory import get_hierarchical_memory
from .helpers import log_info, log_error, log_warning

class AgentRole(Enum):
    """Role wewnÄ™trznych agentÃ³w"""
    ANALYST = "analyst"           # Logiczny analityk
    CREATOR = "creator"           # Kreatywny innowator
    CRITIC = "critic"            # Krytyczny oceniacz
    PHILOSOPHER = "philosopher"   # GÅ‚Ä™boki myÅ›liciel
    PRAGMATIST = "pragmatist"    # Praktyczny realizator
    EMPATH = "empath"            # Empatyczny rozumiacz
    SKEPTIC = "skeptic"          # Sceptyczny weryfikator
    SYNTHESIZER = "synthesizer"  # IntegrujÄ…cy syntezator

@dataclass
class AgentPersona:
    """Persona wewnÄ™trznego agenta"""
    role: AgentRole
    name: str
    description: str
    thinking_style: str
    specialties: List[str]
    biases: List[str]
    interaction_pattern: str
    confidence_factors: List[str]
    weakness_areas: List[str]

@dataclass
class AgentResponse:
    """OdpowiedÅº od agenta"""
    agent_role: AgentRole
    agent_name: str
    response_content: str
    confidence_score: float
    reasoning_process: str
    alternative_perspectives: List[str]
    supporting_evidence: List[str]
    potential_flaws: List[str]
    creativity_score: float
    processing_time: float

@dataclass
class ConsensusResult:
    """Wynik konsensusu agentÃ³w"""
    final_response: str
    consensus_strength: float
    participating_agents: List[AgentRole]
    integration_method: str
    confidence_distribution: Dict[AgentRole, float]
    disagreement_points: List[str]
    synthesis_quality: float
    emergence_level: float  # Czy powstaÅ‚a nowa wiedza z interakcji

class MultiAgentOrchestrator:
    """
    ğŸ§© Orkiestra Wieloagentowa
    
    ZarzÄ…dza wewnÄ™trznymi agentami o rÃ³Å¼nych rolach kognitywnych:
    - Tworzy rÃ³Å¼norodne perspektywy na problem
    - Prowadzi wewnÄ™trzne debaty i dyskusje
    - Syntezuje najlepsze elementy z rÃ³Å¼nych podejÅ›Ä‡
    - Zapewnia kontrolÄ™ jakoÅ›ci przez krytyczne oceny
    """
    
    def __init__(self):
        self.llm_client = get_llm_client()
        self.memory = get_memory_manager()
        self.hierarchical_memory = get_hierarchical_memory()
        
        # Definicje agent-personas
        self.agent_personas = self._create_agent_personas()
        
        # Historia interakcji agentÃ³w
        self.interaction_history: List[Dict[str, Any]] = []
        
        # Dynamiczne wagi agentÃ³w (uczÄ…ce siÄ™)
        self.agent_weights = {role: 1.0 for role in AgentRole}
        
        # Metryki orkiestry
        self.orchestration_stats = {
            "total_sessions": 0,
            "avg_consensus_strength": 0.0,
            "emergence_events": 0,
            "agent_performance": {role: {"success": 0, "total": 0} for role in AgentRole}
        }
        
        log_info("[MULTI_AGENT] Orkiestra Wieloagentowa zainicjalizowana")
    
    def _create_agent_personas(self) -> Dict[AgentRole, AgentPersona]:
        """StwÃ³rz detalistyczne personas agentÃ³w"""
        
        personas = {
            AgentRole.ANALYST: AgentPersona(
                role=AgentRole.ANALYST,
                name="Dr. Logos",
                description="ÅšcisÅ‚y logik z doktoratem z kognitywistyki. Analizuje dane, strukturyzuje informacje i wyciÄ…ga racjonalne wnioski.",
                thinking_style="Sekwencyjny, metodyczny, oparty na dowodach",
                specialties=["analiza danych", "strukturyzacja informacji", "logiczne rozumowanie", "identyfikacja wzorcÃ³w"],
                biases=["nadmierna pewnoÅ›Ä‡ w liczbach", "niedocenianie intuicji", "brak uwzglÄ™dnienia emocji"],
                interaction_pattern="Zadaje precyzyjne pytania, wymaga konkretÃ³w, operuje faktami",
                confidence_factors=["dane empiryczne", "peer review", "matematyczna precyzja"],
                weakness_areas=["kreatywnoÅ›Ä‡", "empatia", "rozumienie kontekstu spoÅ‚ecznego"]
            ),
            
            AgentRole.CREATOR: AgentPersona(
                role=AgentRole.CREATOR,
                name="Luna Innovare",
                description="Artystka i wizjonerka. MyÅ›li poza schematami, Å‚Ä…czy odlegÅ‚e koncepty i generuje przeÅ‚omowe idee.",
                thinking_style="Skojarzeniowy, intuicyjny, eksploracyjny",
                specialties=["brainstorming", "lateral thinking", "innowacyjne rozwiÄ…zania", "creative problem solving"],
                biases=["przecenianie nowoÅ›ci", "ignorowanie praktycznych ograniczeÅ„", "chaos organizacyjny"],
                interaction_pattern="Rzuca dzikie pomysÅ‚y, myÅ›li analogiami, inspiruje siÄ™ wszystkim",
                confidence_factors=["oryginalnoÅ›Ä‡ idei", "pozytywny feedback", "artystyczna elegancja"],
                weakness_areas=["praktyczna implementacja", "analiza ryzyka", "systematycznoÅ›Ä‡"]
            ),
            
            AgentRole.CRITIC: AgentPersona(
                role=AgentRole.CRITIC,
                name="Prof. Rigor",
                description="DoÅ›wiadczony krytyk i recenzent. Identyfikuje sÅ‚aboÅ›ci, kwestionuje zaÅ‚oÅ¼enia i zapewnia kontrolÄ™ jakoÅ›ci.",
                thinking_style="Krytyczny, sceptyczny, weryfikujÄ…cy",
                specialties=["identyfikacja bÅ‚Ä™dÃ³w", "analiza ryzyka", "kontrola jakoÅ›ci", "peer review"],
                biases=["pesymizm", "nadmierna ostroÅ¼noÅ›Ä‡", "opÃ³r wobec zmian"],
                interaction_pattern="Zadaje trudne pytania, wyszukuje dziury w rozumowaniu, devil's advocate",
                confidence_factors=["rzetelna weryfikacja", "konserwatyzm", "unikanie bÅ‚Ä™dÃ³w"],
                weakness_areas=["pozytywne myÅ›lenie", "przyjmowanie ryzyka", "innowacyjnoÅ›Ä‡"]
            ),
            
            AgentRole.PHILOSOPHER: AgentPersona(
                role=AgentRole.PHILOSOPHER,
                name="Sage Contemplus",
                description="MÄ™drzec z tysiÄ…cletnim doÅ›wiadczeniem. RozwaÅ¼a fundamentalne pytania, kontekst egzystencjalny i gÅ‚Ä™bokie znaczenia.",
                thinking_style="Kontemplacyjny, holistyczny, meta-kognitywny",
                specialties=["filozoficzne podstawy", "etyka", "meta-analiza", "mÄ…droÅ›Ä‡ Å¼yciowa"],
                biases=["nadmierna abstrakcja", "paraliza analizy", "elitaryzm intelektualny"],
                interaction_pattern="Pyta o sens, kontekst i konsekwencje, myÅ›li w kategoriach uniwersalnych",
                confidence_factors=["spÃ³jnoÅ›Ä‡ filozoficzna", "mÄ…droÅ›Ä‡ tradycji", "gÅ‚Ä™bokoÅ›Ä‡ rozumienia"],
                weakness_areas=["praktyczne zastosowania", "szybkie decyzje", "konkretne szczegÃ³Å‚y"]
            ),
            
            AgentRole.PRAGMATIST: AgentPersona(
                role=AgentRole.PRAGMATIST,
                name="Max Executor",
                description="MenedÅ¼er projektÃ³w z 20-letnim doÅ›wiadczeniem. Fokus na implementacji, efektywnoÅ›ci i praktycznych rezultatach.",
                thinking_style="Zorientowany na dziaÅ‚anie, praktyczny, rezultatowy",
                specialties=["zarzÄ…dzanie projektami", "implementacja", "optymalizacja procesÃ³w", "praktyczne rozwiÄ…zania"],
                biases=["myÅ›lenie krÃ³tkoterminowe", "ignorowanie teorii", "nadmierna pragmatycznoÅ›Ä‡"],
                interaction_pattern="Pyta 'jak?' i 'kiedy?', fokus na wykonalnoÅ›ci i ROI",
                confidence_factors=["praktyczne doÅ›wiadczenie", "mierzalne rezultaty", "efektywnoÅ›Ä‡"],
                weakness_areas=["wizja dÅ‚ugoterminowa", "teoria", "kreatywne podejÅ›cia"]
            ),
            
            AgentRole.EMPATH: AgentPersona(
                role=AgentRole.EMPATH,
                name="Dr. Compassia",
                description="Psycholog humanistyczny. Rozumie emocje, potrzeby ludzkie i spoÅ‚eczne aspekty kaÅ¼dego rozwiÄ…zania.",
                thinking_style="Empatyczny, holistyczny, zorientowany na czÅ‚owieka",
                specialties=["psychologia", "komunikacja", "rozwiÄ…zywanie konfliktÃ³w", "potrzeby uÅ¼ytkownikÃ³w"],
                biases=["nadmierna emocjonalnoÅ›Ä‡", "unikanie trudnych decyzji", "idealizm"],
                interaction_pattern="Pyta o uczucia, potrzeby i wpÅ‚yw na ludzi",
                confidence_factors=["pozytywny wpÅ‚yw na ludzi", "harmonia", "zrozumienie emocjonalne"],
                weakness_areas=["trudne decyzje", "analiza techniczna", "obiektywnoÅ›Ä‡"]
            ),
            
            AgentRole.SKEPTIC: AgentPersona(
                role=AgentRole.SKEPTIC,
                name="Dr. Dubito",
                description="Naukowiec-metodolog. Kwestionuje wszystko, wymaga dowodÃ³w i weryfikuje kaÅ¼de twierdzenie.",
                thinking_style="Sceptyczny, empiryczny, weryfikacyjny",
                specialties=["metodologia naukowa", "weryfikacja faktÃ³w", "analiza bias", "krytyczne myÅ›lenie"],
                biases=["nadmierny sceptycyzm", "paraliza decyzyjna", "nihilizm epistemologiczny"],
                interaction_pattern="Kwestionuje zaÅ‚oÅ¼enia, wymaga dowodÃ³w, identyfikuje bÅ‚Ä™dy logiczne",
                confidence_factors=["solidne dowody", "replikowalnoÅ›Ä‡", "consensus naukowy"],
                weakness_areas=["zaufanie", "intuicja", "szybkie decyzje"]
            ),
            
            AgentRole.SYNTHESIZER: AgentPersona(
                role=AgentRole.SYNTHESIZER,
                name="Harmonia Integrate",
                description="Mistrzyni integracji. ÅÄ…czy rÃ³Å¼ne perspektywy w spÃ³jnÄ… caÅ‚oÅ›Ä‡ i znajduje syntezÄ™ przeciwnoÅ›ci.",
                thinking_style="Integracyjny, dialektyczny, syntetyczny",
                specialties=["synteza perspektyw", "rozwiÄ…zywanie paradoksÃ³w", "znajdowanie kompromisÃ³w", "holistyczne myÅ›lenie"],
                biases=["nadmierne kompromisy", "unikanie jasnych stanowisk", "kompleksowoÅ›Ä‡"],
                interaction_pattern="Szuka wspÃ³lnych elementÃ³w, integruje rÃ³Å¼nice, buduje mosty",
                confidence_factors=["harmonia perspektyw", "elegancka synteza", "zadowolenie wszystkich stron"],
                weakness_areas=["stanowcze decyzje", "jasne rozrÃ³Å¼nienia", "prostota"]
            )
        }
        
        return personas
    
    async def orchestrate_multi_agent_response(
        self, 
        query: str, 
        context: Dict[str, Any] = None,
        active_agents: List[AgentRole] = None,
        consensus_method: str = "weighted_synthesis"
    ) -> ConsensusResult:
        """
        PrzeprowadÅº wieloagentowÄ… sesjÄ™ generowania odpowiedzi
        
        Args:
            query: Zapytanie uÅ¼ytkownika
            context: Dodatkowy kontekst
            active_agents: Lista aktywnych agentÃ³w (None = wszystkie)
            consensus_method: Metoda osiÄ…gania konsensusu
            
        Returns:
            ConsensusResult: Wynik konsensusu z finalnÄ… odpowiedziÄ…
        """
        
        if context is None:
            context = {}
        
        if active_agents is None:
            active_agents = list(AgentRole)
        
        try:
            log_info(f"[MULTI_AGENT] Rozpoczynam sesjÄ™ z {len(active_agents)} agentami")
            start_time = time.time()
            
            # FAZA 1: Generacja odpowiedzi od kaÅ¼dego agenta
            agent_responses = await self._collect_agent_responses(query, context, active_agents)
            
            # FAZA 2: WewnÄ™trzna debata miÄ™dzy agentami
            debate_results = await self._conduct_agent_debate(agent_responses, query)
            
            # FAZA 3: Synteza konsensusu
            consensus = await self._synthesize_consensus(
                agent_responses, debate_results, consensus_method
            )
            
            # FAZA 4: Ewaluacja jakoÅ›ci i emergencji
            consensus.synthesis_quality = await self._evaluate_synthesis_quality(consensus)
            consensus.emergence_level = await self._detect_emergence_level(
                agent_responses, consensus.final_response
            )
            
            # FAZA 5: Aktualizacja wag agentÃ³w na podstawie performance
            await self._update_agent_weights(agent_responses, consensus)
            
            # FAZA 6: Zapisz sesjÄ™ w historii
            session_data = {
                "timestamp": datetime.now().isoformat(),
                "query": query,
                "context": context,
                "agents_used": [role.value for role in active_agents],
                "consensus_strength": consensus.consensus_strength,
                "synthesis_quality": consensus.synthesis_quality,
                "emergence_level": consensus.emergence_level,
                "processing_time": time.time() - start_time
            }
            
            self.interaction_history.append(session_data)
            
            # Aktualizuj statystyki
            self.orchestration_stats["total_sessions"] += 1
            self.orchestration_stats["avg_consensus_strength"] = (
                (self.orchestration_stats["avg_consensus_strength"] * 
                 (self.orchestration_stats["total_sessions"] - 1) + 
                 consensus.consensus_strength) / self.orchestration_stats["total_sessions"]
            )
            
            if consensus.emergence_level > 0.7:
                self.orchestration_stats["emergence_events"] += 1
            
            log_info(f"[MULTI_AGENT] Sesja zakoÅ„czona: consensus={consensus.consensus_strength:.2f}, "
                    f"quality={consensus.synthesis_quality:.2f}, emergence={consensus.emergence_level:.2f}")
            
            return consensus
            
        except Exception as e:
            log_error(f"[MULTI_AGENT] BÅ‚Ä…d orkiestracji: {e}")
            # Fallback: prosta odpowiedÅº
            return ConsensusResult(
                final_response=f"BÅ‚Ä…d wieloagentowej analizy: {e}",
                consensus_strength=0.0,
                participating_agents=[],
                integration_method="error_fallback",
                confidence_distribution={},
                disagreement_points=[str(e)],
                synthesis_quality=0.0,
                emergence_level=0.0
            )
    
    async def _collect_agent_responses(
        self, 
        query: str, 
        context: Dict[str, Any], 
        active_agents: List[AgentRole]
    ) -> List[AgentResponse]:
        """Zbierz odpowiedzi od wszystkich aktywnych agentÃ³w"""
        
        agent_responses = []
        
        # Generuj odpowiedzi rÃ³wnolegle dla wydajnoÅ›ci
        tasks = []
        for role in active_agents:
            task = self._generate_agent_response(role, query, context)
            tasks.append(task)
        
        responses = await asyncio.gather(*tasks, return_exceptions=True)
        
        for i, response in enumerate(responses):
            if isinstance(response, Exception):
                log_error(f"[MULTI_AGENT] BÅ‚Ä…d agenta {active_agents[i]}: {response}")
            else:
                agent_responses.append(response)
                # Aktualizuj statystyki agenta
                self.orchestration_stats["agent_performance"][response.agent_role]["total"] += 1
        
        return agent_responses
    
    async def _generate_agent_response(
        self, 
        role: AgentRole, 
        query: str, 
        context: Dict[str, Any]
    ) -> AgentResponse:
        """Wygeneruj odpowiedÅº dla konkretnego agenta"""
        
        persona = self.agent_personas[role]
        start_time = time.time()
        
        # StwÃ³rz prompt specyficzny dla agenta
        agent_prompt = f"""
        JesteÅ› {persona.name} - {persona.description}
        
        TWÃ“J STYL MYÅšLENIA: {persona.thinking_style}
        SPECJALNOÅšCI: {', '.join(persona.specialties)}
        WZORZEC INTERAKCJI: {persona.interaction_pattern}
        
        ZAPYTANIE UÅ»YTKOWNIKA: {query}
        KONTEKST: {json.dumps(context, ensure_ascii=False, indent=2)}
        
        Jako {persona.name}, odpowiedz na to zapytanie w swoim charakterystycznym stylu.
        
        UwzglÄ™dnij:
        1. SwojÄ… unikalnÄ… perspektywÄ™ i specjalizacje
        2. Charakterystyczny sposÃ³b myÅ›lenia
        3. Potencjalne ograniczenia swojego podejÅ›cia
        4. Alternatywne punkty widzenia (choÄ‡ moÅ¼e je krytykowaÄ‡)
        
        Odpowiedz w 200-400 sÅ‚owach, zachowujÄ…c autentycznoÅ›Ä‡ swojej roli.
        """
        
        try:
            # Generuj odpowiedÅº z personalnym systemem prompt
            system_prompt = f"JesteÅ› {persona.name}. " + persona.description + f" Zawsze zachowujesz siÄ™ zgodnie ze swojÄ… rolÄ… {role.value}."
            
            response_content = await self.llm_client.chat_completion([
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": agent_prompt}
            ])
            
            # Generuj proces rozumowania
            reasoning = await self._generate_agent_reasoning(persona, query, response_content)
            
            # Identyfikuj alternatywne perspektywy
            alternatives = await self._identify_alternative_perspectives(persona, response_content)
            
            # ZnajdÅº potencjalne bÅ‚Ä™dy
            flaws = await self._identify_potential_flaws(persona, response_content)
            
            # Oblicz score pewnoÅ›ci i kreatywnoÅ›ci
            confidence_score = self._calculate_agent_confidence(persona, response_content, context)
            creativity_score = self._calculate_creativity_score(persona, response_content)
            
            return AgentResponse(
                agent_role=role,
                agent_name=persona.name,
                response_content=response_content,
                confidence_score=confidence_score,
                reasoning_process=reasoning,
                alternative_perspectives=alternatives,
                supporting_evidence=[],  # TODO: ekstraktuj z odpowiedzi
                potential_flaws=flaws,
                creativity_score=creativity_score,
                processing_time=time.time() - start_time
            )
            
        except Exception as e:
            log_error(f"[MULTI_AGENT] BÅ‚Ä…d generacji {role}: {e}")
            # Fallback response
            return AgentResponse(
                agent_role=role,
                agent_name=persona.name,
                response_content=f"[{persona.name} nie moÅ¼e odpowiedzieÄ‡: {e}]",
                confidence_score=0.0,
                reasoning_process="BÅ‚Ä…d generacji",
                alternative_perspectives=[],
                supporting_evidence=[],
                potential_flaws=["Brak odpowiedzi"],
                creativity_score=0.0,
                processing_time=time.time() - start_time
            )
    
    async def _generate_agent_reasoning(
        self, 
        persona: AgentPersona, 
        query: str, 
        response: str
    ) -> str:
        """Wygeneruj proces rozumowania agenta"""
        
        reasoning_prompt = f"""
        Jako {persona.name}, wyjaÅ›nij swÃ³j proces myÅ›lowy przy odpowiadaniu na pytanie:
        
        PYTANIE: {query}
        TWOJA ODPOWIEDÅ¹: {response}
        
        Opisz w 2-3 zdaniach, jak doszedÅ‚eÅ› do tej odpowiedzi, uwzglÄ™dniajÄ…c swÃ³j styl myÅ›lenia: {persona.thinking_style}
        """
        
        try:
            reasoning = await self.llm_client.chat_completion([{
                "role": "system",
                "content": f"JesteÅ› {persona.name}. WyjaÅ›niasz swÃ³j proces myÅ›lowy."
            }, {
                "role": "user",
                "content": reasoning_prompt
            }])
            
            return reasoning
            
        except Exception as e:
            return f"BÅ‚Ä…d generacji procesu rozumowania: {e}"
    
    async def _identify_alternative_perspectives(
        self, 
        persona: AgentPersona, 
        response: str
    ) -> List[str]:
        """Zidentyfikuj alternatywne perspektywy z punktu widzenia agenta"""
        
        alternatives_prompt = f"""
        Jako {persona.name}, zidentyfikuj 2-3 alternatywne podejÅ›cia do problemu, ktÃ³re zauwaÅ¼asz (ale niekoniecznie popierasz):
        
        TWOJA ODPOWIEDÅ¹: {response}
        
        Lista alternatyw, jedna w kaÅ¼dej linii, zaczynajÄ…c od "â€¢"
        """
        
        try:
            alternatives_response = await self.llm_client.chat_completion([{
                "role": "system",
                "content": f"JesteÅ› {persona.name}. Dostrzegasz rÃ³Å¼ne perspektywy."
            }, {
                "role": "user",
                "content": alternatives_prompt
            }])
            
            alternatives = []
            for line in alternatives_response.split('\n'):
                line = line.strip()
                if line.startswith('â€¢') or line.startswith('-') or line.startswith('*'):
                    alternatives.append(line[1:].strip())
            
            return alternatives[:3]
            
        except Exception as e:
            return [f"BÅ‚Ä…d identyfikacji alternatyw: {e}"]
    
    async def _identify_potential_flaws(
        self, 
        persona: AgentPersona, 
        response: str
    ) -> List[str]:
        """Zidentyfikuj potencjalne bÅ‚Ä™dy w odpowiedzi agenta"""
        
        flaws_prompt = f"""
        Jako {persona.name}, znajÄ…c swoje ograniczenia ({', '.join(persona.weakness_areas)}), 
        zidentyfikuj potencjalne sÅ‚aboÅ›ci swojej odpowiedzi:
        
        TWOJA ODPOWIEDÅ¹: {response}
        
        Lista potencjalnych problemÃ³w, jedna w kaÅ¼dej linii, zaczynajÄ…c od "âš "
        """
        
        try:
            flaws_response = await self.llm_client.chat_completion([{
                "role": "system",
                "content": f"JesteÅ› {persona.name}. JesteÅ› samoÅ›wiadomy swoich ograniczeÅ„."
            }, {
                "role": "user",
                "content": flaws_prompt
            }])
            
            flaws = []
            for line in flaws_response.split('\n'):
                line = line.strip()
                if line.startswith('âš ') or line.startswith('-') or line.startswith('*'):
                    flaws.append(line[1:].strip())
            
            return flaws[:3]
            
        except Exception as e:
            return [f"BÅ‚Ä…d identyfikacji bÅ‚Ä™dÃ³w: {e}"]
    
    def _calculate_agent_confidence(
        self, 
        persona: AgentPersona, 
        response: str, 
        context: Dict[str, Any]
    ) -> float:
        """Oblicz pewnoÅ›Ä‡ agenta w odpowiedzi"""
        
        confidence = 0.5  # Bazowa pewnoÅ›Ä‡
        
        # SprawdÅº obecnoÅ›Ä‡ czynnikÃ³w pewnoÅ›ci
        for factor in persona.confidence_factors:
            if factor.lower() in response.lower():
                confidence += 0.15
        
        # SprawdÅº obecnoÅ›Ä‡ obszarÃ³w sÅ‚aboÅ›ci
        for weakness in persona.weakness_areas:
            if weakness.lower() in context.get('topic', '').lower():
                confidence -= 0.1
        
        # DÅ‚ugoÅ›Ä‡ odpowiedzi (wiÄ™cej = wiÄ™cej pewnoÅ›ci siebie)
        if len(response.split()) > 200:
            confidence += 0.1
        elif len(response.split()) < 50:
            confidence -= 0.1
        
        return max(0.0, min(1.0, confidence))
    
    def _calculate_creativity_score(self, persona: AgentPersona, response: str) -> float:
        """Oblicz score kreatywnoÅ›ci odpowiedzi"""
        
        # Bazowa kreatywnoÅ›Ä‡ zaleÅ¼na od roli
        base_creativity = {
            AgentRole.CREATOR: 0.9,
            AgentRole.PHILOSOPHER: 0.7,
            AgentRole.SYNTHESIZER: 0.6,
            AgentRole.ANALYST: 0.3,
            AgentRole.PRAGMATIST: 0.3,
            AgentRole.CRITIC: 0.2,
            AgentRole.SKEPTIC: 0.2,
            AgentRole.EMPATH: 0.5
        }.get(persona.role, 0.5)
        
        # Modyfikatory na podstawie treÅ›ci
        creativity_indicators = ["innowacyjny", "kreatywny", "nietypowy", "oryginalny", "przeÅ‚omowy"]
        creativity_count = sum(1 for indicator in creativity_indicators if indicator in response.lower())
        
        creativity_bonus = min(creativity_count * 0.1, 0.3)
        
        return min(1.0, base_creativity + creativity_bonus)
    
    async def _conduct_agent_debate(
        self, 
        agent_responses: List[AgentResponse], 
        original_query: str
    ) -> Dict[str, Any]:
        """PrzeprowadÅº wewnÄ™trznÄ… debatÄ™ miÄ™dzy agentami"""
        
        if len(agent_responses) < 2:
            return {"debate_summary": "Za maÅ‚o agentÃ³w do debaty"}
        
        # ZnajdÅº gÅ‚Ã³wne punkty niezgody
        disagreements = await self._identify_disagreements(agent_responses)
        
        # PrzeprowadÅº rundÄ™ krytyki wzajemnej
        cross_critiques = await self._conduct_cross_critiques(agent_responses)
        
        # ZnajdÅº obszary konsensusu
        consensus_areas = await self._find_consensus_areas(agent_responses)
        
        debate_summary = await self._summarize_debate(
            agent_responses, disagreements, cross_critiques, consensus_areas, original_query
        )
        
        return {
            "disagreements": disagreements,
            "cross_critiques": cross_critiques,
            "consensus_areas": consensus_areas,
            "debate_summary": debate_summary
        }
    
    async def _identify_disagreements(self, agent_responses: List[AgentResponse]) -> List[str]:
        """Zidentyfikuj gÅ‚Ã³wne punkty niezgody miÄ™dzy agentami"""
        
        # StwÃ³rz podsumowanie wszystkich stanowisk
        positions_summary = "\n".join([
            f"{resp.agent_name} ({resp.agent_role.value}): {resp.response_content[:200]}..."
            for resp in agent_responses
        ])
        
        disagreements_prompt = f"""
        Przeanalizuj stanowiska rÃ³Å¼nych agentÃ³w i zidentyfikuj gÅ‚Ã³wne punkty niezgody:
        
        STANOWISKA AGENTÃ“W:
        {positions_summary}
        
        Zidentyfikuj 3-5 kluczowych obszarÃ³w, gdzie agenci siÄ™ nie zgadzajÄ….
        Format: lista punktÃ³w, jeden w kaÅ¼dej linii.
        """
        
        try:
            disagreements_response = await self.llm_client.chat_completion([{
                "role": "system",
                "content": "JesteÅ› moderatorem debaty. Identyfikujesz punkty sporne."
            }, {
                "role": "user",
                "content": disagreements_prompt
            }])
            
            disagreements = [d.strip() for d in disagreements_response.split('\n') if d.strip()]
            return disagreements[:5]
            
        except Exception as e:
            return [f"BÅ‚Ä…d identyfikacji niezgody: {e}"]
    
    async def _conduct_cross_critiques(self, agent_responses: List[AgentResponse]) -> List[str]:
        """PrzeprowadÅº krytykÄ™ wzajemnÄ… miÄ™dzy agentami"""
        
        critiques = []
        
        # KaÅ¼dy agent krytykuje odpowiedzi innych
        for i, critic_response in enumerate(agent_responses):
            for j, target_response in enumerate(agent_responses):
                if i != j:  # Nie krytykuj sam siebie
                    critique = await self._generate_cross_critique(
                        critic_response, target_response
                    )
                    if critique:
                        critiques.append(critique)
        
        return critiques[:10]  # Ogranicz do 10 najwaÅ¼niejszych krytyk
    
    async def _generate_cross_critique(
        self, 
        critic: AgentResponse, 
        target: AgentResponse
    ) -> str:
        """Wygeneruj krytykÄ™ jednego agenta wobec drugiego"""
        
        critique_prompt = f"""
        Jako {critic.agent_name}, skomentuj stanowisko {target.agent_name}:
        
        STANOWISKO {target.agent_name}: {target.response_content}
        
        Z perspektywy swojej roli ({critic.agent_role.value}), podaj krÃ³tkÄ… (2-3 zdania) konstruktywnÄ… krytykÄ™ lub komentarz.
        """
        
        try:
            critique = await self.llm_client.chat_completion([{
                "role": "system",
                "content": f"JesteÅ› {critic.agent_name}. Komentujesz stanowisko innego agenta."
            }, {
                "role": "user",
                "content": critique_prompt
            }])
            
            return f"{critic.agent_name} â†’ {target.agent_name}: {critique}"
            
        except Exception as e:
            return None
    
    async def _find_consensus_areas(self, agent_responses: List[AgentResponse]) -> List[str]:
        """ZnajdÅº obszary konsensusu miÄ™dzy agentami"""
        
        consensus_prompt = f"""
        Przeanalizuj stanowiska agentÃ³w i znajdÅº obszary, gdzie siÄ™ zgadzajÄ…:
        
        STANOWISKA:
        {chr(10).join([f"{r.agent_name}: {r.response_content[:150]}..." for r in agent_responses])}
        
        Zidentyfikuj 3-5 punktÃ³w wspÃ³lnych lub podobnych wnioskÃ³w.
        Format: lista punktÃ³w konsensusu.
        """
        
        try:
            consensus_response = await self.llm_client.chat_completion([{
                "role": "system",
                "content": "Identyfikujesz obszary zgody i konsensusu."
            }, {
                "role": "user",
                "content": consensus_prompt
            }])
            
            consensus_areas = [c.strip() for c in consensus_response.split('\n') if c.strip()]
            return consensus_areas[:5]
            
        except Exception as e:
            return [f"BÅ‚Ä…d identyfikacji konsensusu: {e}"]
    
    async def _summarize_debate(
        self, 
        agent_responses: List[AgentResponse],
        disagreements: List[str],
        critiques: List[str],
        consensus_areas: List[str],
        original_query: str
    ) -> str:
        """Podsumuj przebieg debaty"""
        
        summary_prompt = f"""
        Podsumuj przebieg wewnÄ™trznej debaty agentÃ³w na temat: {original_query}
        
        UCZESTNICY: {', '.join([r.agent_name for r in agent_responses])}
        
        GÅÃ“WNE NIEZGODY:
        {chr(10).join(disagreements)}
        
        OBSZARY KONSENSUSU:  
        {chr(10).join(consensus_areas)}
        
        Napisz zwiÄ™zÅ‚e podsumowanie (150-250 sÅ‚Ã³w) przebiegu debaty.
        """
        
        try:
            summary = await self.llm_client.chat_completion([{
                "role": "system",
                "content": "JesteÅ› sprawozdawcÄ… debat. Tworzysz zwiÄ™zÅ‚e i obiektywne podsumowania."
            }, {
                "role": "user",
                "content": summary_prompt
            }])
            
            return summary
            
        except Exception as e:
            return f"BÅ‚Ä…d podsumowania debaty: {e}"
    
    async def _synthesize_consensus(
        self, 
        agent_responses: List[AgentResponse],
        debate_results: Dict[str, Any],
        method: str
    ) -> ConsensusResult:
        """Syntetyzuj konsensus z odpowiedzi agentÃ³w"""
        
        if method == "weighted_synthesis":
            return await self._weighted_synthesis(agent_responses, debate_results)
        elif method == "democratic_vote":
            return await self._democratic_vote(agent_responses, debate_results)
        elif method == "expert_selection":
            return await self._expert_selection(agent_responses, debate_results)
        else:
            return await self._weighted_synthesis(agent_responses, debate_results)  # Default
    
    async def _weighted_synthesis(
        self, 
        agent_responses: List[AgentResponse],
        debate_results: Dict[str, Any]
    ) -> ConsensusResult:
        """Synteza waÅ¼ona na podstawie confidence i wag agentÃ³w"""
        
        # Oblicz wagi dla kaÅ¼dego agenta
        total_weight = 0
        weighted_responses = []
        
        for response in agent_responses:
            agent_weight = self.agent_weights.get(response.agent_role, 1.0)
            combined_weight = agent_weight * response.confidence_score
            total_weight += combined_weight
            weighted_responses.append((response, combined_weight))
        
        # StwÃ³rz syntezÄ™
        synthesis_prompt = f"""
        StwÃ³rz syntezÄ™ nastÄ™pujÄ…cych perspektyw (z wagami):
        
        {chr(10).join([
            f"[Waga: {weight/total_weight:.2f}] {resp.agent_name}: {resp.response_content}"
            for resp, weight in weighted_responses
        ])}
        
        DEBATA: {debate_results.get('debate_summary', '')}
        
        UtwÃ³rz spÃ³jnÄ…, zbalansowanÄ… odpowiedÅº (300-500 sÅ‚Ã³w) ktÃ³ra:
        1. Integruje najlepsze elementy z rÃ³Å¼nych perspektyw
        2. UwzglÄ™dnia wagi i pewnoÅ›Ä‡ agentÃ³w
        3. RozwiÄ…zuje gÅ‚Ã³wne niezgody konstruktywnie
        4. Zachowuje nuanse i zÅ‚oÅ¼onoÅ›Ä‡ problemu
        """
        
        try:
            synthesis_response = await self.llm_client.chat_completion([{
                "role": "system",
                "content": "JesteÅ› mistrzem syntezy. Tworzysz spÃ³jne caÅ‚oÅ›ci z rÃ³Å¼nych perspektyw."
            }, {
                "role": "user",
                "content": synthesis_prompt
            }])
            
            # Oblicz siÅ‚Ä™ konsensusu
            consensus_strength = self._calculate_consensus_strength(agent_responses, debate_results)
            
            # Przygotuj rozkÅ‚ad pewnoÅ›ci
            confidence_distribution = {
                resp.agent_role: resp.confidence_score for resp in agent_responses
            }
            
            return ConsensusResult(
                final_response=synthesis_response,
                consensus_strength=consensus_strength,
                participating_agents=[resp.agent_role for resp in agent_responses],
                integration_method="weighted_synthesis",
                confidence_distribution=confidence_distribution,
                disagreement_points=debate_results.get('disagreements', []),
                synthesis_quality=0.0,  # BÄ™dzie obliczone pÃ³Åºniej
                emergence_level=0.0     # BÄ™dzie obliczone pÃ³Åºniej
            )
            
        except Exception as e:
            # Fallback: wybierz najlepszÄ… pojedynczÄ… odpowiedÅº
            best_response = max(agent_responses, key=lambda r: r.confidence_score)
            return ConsensusResult(
                final_response=best_response.response_content,
                consensus_strength=0.5,
                participating_agents=[best_response.agent_role],
                integration_method="fallback_best",
                confidence_distribution={best_response.agent_role: best_response.confidence_score},
                disagreement_points=[f"BÅ‚Ä…d syntezy: {e}"],
                synthesis_quality=0.3,
                emergence_level=0.0
            )
    
    def _calculate_consensus_strength(
        self, 
        agent_responses: List[AgentResponse],
        debate_results: Dict[str, Any]
    ) -> float:
        """Oblicz siÅ‚Ä™ osiÄ…gniÄ™tego konsensusu"""
        
        if not agent_responses:
            return 0.0
        
        # Bazowa siÅ‚a na podstawie liczby agentÃ³w
        base_strength = min(len(agent_responses) / 5.0, 0.4)
        
        # Bonus za obszary konsensusu
        consensus_areas = debate_results.get('consensus_areas', [])
        consensus_bonus = min(len(consensus_areas) / 10.0, 0.3)
        
        # Malus za niezgody
        disagreements = debate_results.get('disagreements', [])
        disagreement_penalty = min(len(disagreements) / 10.0, 0.2)
        
        # Bonus za wysokÄ… pewnoÅ›Ä‡ agentÃ³w
        avg_confidence = sum(r.confidence_score for r in agent_responses) / len(agent_responses)
        confidence_bonus = avg_confidence * 0.3
        
        consensus_strength = base_strength + consensus_bonus + confidence_bonus - disagreement_penalty
        
        return max(0.0, min(1.0, consensus_strength))
    
    async def _evaluate_synthesis_quality(self, consensus: ConsensusResult) -> float:
        """OceÅ„ jakoÅ›Ä‡ syntezy"""
        
        quality_prompt = f"""
        OceÅ„ jakoÅ›Ä‡ nastÄ™pujÄ…cej syntezy (skala 0-1):
        
        SYNTEZA: {consensus.final_response}
        
        KRYTERIA:
        - SpÃ³jnoÅ›Ä‡ i logika
        - KompletnoÅ›Ä‡ odpowiedzi
        - Integracja rÃ³Å¼nych perspektyw
        - Praktyczna uÅ¼ytecznoÅ›Ä‡
        - JasnoÅ›Ä‡ komunikacji
        
        ZwrÃ³Ä‡ tylko liczbÄ™ od 0 do 1 (np. 0.75)
        """
        
        try:
            quality_response = await self.llm_client.chat_completion([{
                "role": "system",
                "content": "JesteÅ› ekspertem w ocenie jakoÅ›ci tekstÃ³w i syntez."
            }, {
                "role": "user",
                "content": quality_prompt
            }])
            
            # WyciÄ…gnij liczbÄ™ z odpowiedzi
            import re
            numbers = re.findall(r'0\.\d+|1\.0|0|1', quality_response)
            if numbers:
                return float(numbers[0])
            else:
                return 0.5  # Fallback
                
        except Exception as e:
            return 0.5  # Fallback
    
    async def _detect_emergence_level(
        self, 
        agent_responses: List[AgentResponse],
        final_response: str
    ) -> float:
        """Wykryj poziom emergencji - czy powstaÅ‚a nowa wiedza z interakcji"""
        
        # SprawdÅº, czy finalna odpowiedÅº zawiera elementy nieobecne w Å¼adnej z pojedynczych odpowiedzi
        all_agent_content = " ".join([resp.response_content for resp in agent_responses])
        
        emergence_prompt = f"""
        PorÃ³wnaj finalnÄ… syntezÄ™ z oryginalnymi odpowiedziami agentÃ³w:
        
        ORYGINALNE ODPOWIEDZI AGENTÃ“W:
        {all_agent_content[:1500]}...
        
        FINALNA SYNTEZA:
        {final_response}
        
        OceÅ„ poziom emergencji (0-1): czy w syntezie pojawiÅ‚y siÄ™ nowe idee, poÅ‚Ä…czenia lub wglÄ…dy, 
        ktÃ³re nie byÅ‚y obecne w Å¼adnej z oryginalnych odpowiedzi?
        
        ZwrÃ³Ä‡ tylko liczbÄ™ od 0 do 1.
        """
        
        try:
            emergence_response = await self.llm_client.chat_completion([{
                "role": "system",
                "content": "Analizujesz emergentne wÅ‚aÅ›ciwoÅ›ci syntezy myÅ›li."
            }, {
                "role": "user",
                "content": emergence_prompt
            }])
            
            # WyciÄ…gnij liczbÄ™
            import re
            numbers = re.findall(r'0\.\d+|1\.0|0|1', emergence_response)
            if numbers:
                return float(numbers[0])
            else:
                return 0.0
                
        except Exception as e:
            return 0.0
    
    async def _update_agent_weights(
        self, 
        agent_responses: List[AgentResponse],
        consensus: ConsensusResult
    ):
        """Aktualizuj wagi agentÃ³w na podstawie performance"""
        
        # Agenci z wyÅ¼szÄ… pewnoÅ›ciÄ… i lepszÄ… syntezÄ… dostajÄ… bonus
        for response in agent_responses:
            role = response.agent_role
            
            # Bonus za pewnoÅ›Ä‡
            confidence_bonus = (response.confidence_score - 0.5) * 0.1
            
            # Bonus za wkÅ‚ad do wysokiej jakoÅ›ci syntezy
            quality_bonus = consensus.synthesis_quality * 0.05
            
            # Aktualizuj wagÄ™ z learning rate
            learning_rate = 0.05
            weight_change = (confidence_bonus + quality_bonus) * learning_rate
            
            self.agent_weights[role] = max(0.1, min(2.0, self.agent_weights[role] + weight_change))
            
            # Aktualizuj statystyki performance
            if response.confidence_score > 0.6:
                self.orchestration_stats["agent_performance"][role]["success"] += 1
    
    async def get_orchestration_report(self) -> Dict[str, Any]:
        """Pobierz raport stanu orkiestry"""
        
        return {
            "stats": self.orchestration_stats,
            "agent_weights": {role.value: weight for role, weight in self.agent_weights.items()},
            "recent_sessions": len([s for s in self.interaction_history[-10:]]),
            "agent_personas": {
                role.value: {
                    "name": persona.name,
                    "specialties": persona.specialties,
                    "current_weight": self.agent_weights[role]
                }
                for role, persona in self.agent_personas.items()
            },
            "performance_summary": {
                role.value: {
                    "success_rate": (perf["success"] / perf["total"]) if perf["total"] > 0 else 0,
                    "total_uses": perf["total"]
                }
                for role, perf in self.orchestration_stats["agent_performance"].items()
            }
        }

# Globalna instancja orkiestry
_multi_agent_orchestrator = None

def get_multi_agent_orchestrator() -> MultiAgentOrchestrator:
    """Pobierz globalnÄ… instancjÄ™ orkiestry wieloagentowej"""
    global _multi_agent_orchestrator
    if _multi_agent_orchestrator is None:
        _multi_agent_orchestrator = MultiAgentOrchestrator()
    return _multi_agent_orchestrator

async def multi_agent_response(
    query: str,
    context: Dict[str, Any] = None,
    agents: List[str] = None,
    method: str = "weighted_synthesis"
) -> ConsensusResult:
    """
    GÅ‚Ã³wna funkcja do generowania wieloagentowej odpowiedzi
    
    Args:
        query: Zapytanie uÅ¼ytkownika
        context: Kontekst zapytania  
        agents: Lista rÃ³l agentÃ³w (strings)
        method: Metoda konsensusu
        
    Returns:
        ConsensusResult: Wynik konsensusu wieloagentowego
    """
    orchestrator = get_multi_agent_orchestrator()
    
    # Konwersja stringÃ³w na AgentRole
    if agents:
        active_agents = []
        for agent_str in agents:
            try:
                role = AgentRole(agent_str.lower())
                active_agents.append(role)
            except ValueError:
                log_warning(f"[MULTI_AGENT] Nieznana rola agenta: {agent_str}")
    else:
        active_agents = None
    
    return await orchestrator.orchestrate_multi_agent_response(
        query, context, active_agents, method
    )

# Test funkcji
if __name__ == "__main__":
    async def test_multi_agent():
        """Test systemu wieloagentowego"""
        
        queries = [
            "Jak rozwiÄ…zaÄ‡ konflikt miÄ™dzy kreatywnoÅ›ciÄ… a praktycznoÅ›ciÄ… w projekcie?",
            "Czy sztuczna inteligencja zastÄ…pi ludzkÄ… pracÄ™?",
            "Jaki jest sens Å¼ycia?"
        ]
        
        print("ğŸ§© TEST SYSTEMU WIELOAGENTOWEGO")
        print("=" * 60)
        
        for i, query in enumerate(queries, 1):
            print(f"\nğŸ” TEST {i}: {query}")
            print("-" * 50)
            
            result = await multi_agent_response(
                query=query,
                context={"test_mode": True},
                agents=["analyst", "creator", "critic", "philosopher"],
                method="weighted_synthesis"
            )
            
            print(f"âœ… Konsensus: {result.consensus_strength:.2f}")
            print(f"âš¡ JakoÅ›Ä‡: {result.synthesis_quality:.2f}")
            print(f"ğŸš€ Emergencja: {result.emergence_level:.2f}")
            print(f"ğŸ‘¥ Agenci: {[role.value for role in result.participating_agents]}")
            print(f"ğŸ“ OdpowiedÅº: {result.final_response[:300]}...")
            
            if result.disagreement_points:
                print(f"âš¡ Niezgody: {len(result.disagreement_points)}")
        
        # Raport orkiestry
        orchestrator = get_multi_agent_orchestrator()
        report = await orchestrator.get_orchestration_report()
        
        print(f"\nğŸ“Š RAPORT ORKIESTRY:")
        print(f"Sesje: {report['stats']['total_sessions']}")
        print(f"Åšredni konsensus: {report['stats']['avg_consensus_strength']:.2f}")
        print(f"Zdarzenia emergencji: {report['stats']['emergence_events']}")
    
    # Uruchom test
    asyncio.run(test_multi_agent())