#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Advanced Proactive Suggestions System - Zaawansowany system proaktywnych sugestii

Zawiera integracjÄ™ ze stanem psychologicznym AI, modelami uÅ¼ytkownika
i analizÄ… kontekstu konwersacji. System przewiduje potrzeby uÅ¼ytkownika
i proaktywnie generuje trafne sugestie w odpowiednim momencie.
"""

import re
import json
import asyncio
import time
from typing import List, Dict, Any, Optional, Tuple, Union, Set
from collections import defaultdict, Counter, deque

# Import z core
from core.memory import ltm_search_hybrid, stm_get_context
from core.advanced_psychology import get_psyche_state, process_user_message
from core.user_model import user_model_manager
from core.helpers import log_info, log_warning, log_error
from core.semantic import embed_text, cosine_similarity
from core.config import CONTEXT_DICTIONARIES


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANALIZA KONTEKSTU I KONWERSACJI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ConversationAnalyzer:
    """Zaawansowany analizator konwersacji i kontekstu"""
    
    def __init__(self):
        """Inicjalizuje analizator"""
        # SÅ‚owniki tematÃ³w i intencji
        self.topic_keywords = self._initialize_topic_keywords()
        self.intent_patterns = self._initialize_intent_patterns()
        
        # Statystyki i pamiÄ™Ä‡
        self.recent_topics = deque(maxlen=10)  # (timestamp, topic, score)
        self.recent_intents = deque(maxlen=10)  # (timestamp, intent, confidence)
        
        # Analiza dÅ‚ugoterminowa
        self.topic_frequency = Counter()
        self.intent_frequency = Counter()
        
        # PamiÄ™Ä‡ bieÅ¼Ä…cej sesji
        self.session_start = time.time()
        self.message_count = 0
        self.session_topics = set()
        self.session_intents = set()
        
        # Stany i flagi
        self.is_focused_conversation = True
        self.is_casual_conversation = False
        self.awaiting_response = False
        
        # Threshold do klasyfikacji
        self.topic_threshold = 0.3
        self.intent_threshold = 0.25
        
    def _initialize_topic_keywords(self) -> Dict[str, List[str]]:
        """Inicjalizuje sÅ‚ownik sÅ‚Ã³w kluczowych dla tematÃ³w"""
        # Poszerzona lista sÅ‚Ã³w kluczowych z CONTEXT_DICTIONARIES
        topics = {
            "programming": [
                "kod", "program", "funkcja", "klasa", "metoda", "zmienna", "debuguj", "kompiluj",
                "python", "javascript", "java", "c++", "rust", "go", "typescript", "react", 
                "algorytm", "framework", "biblioteka", "api", "backend", "frontend", "baza danych", 
                "sql", "nosql", "error", "bug", "bÅ‚Ä…d", "commit", "git", "github", "merge"
            ],
            "ai_ml": [
                "ai", "sztuczna inteligencja", "uczenie maszynowe", "machine learning", "deep learning",
                "neural network", "sieÄ‡ neuronowa", "gpt", "llm", "embedding", "token", "fine-tuning",
                "prompt", "inference", "model", "pytorch", "tensorflow", "transformer", "chatbot",
                "klasyfikacja", "regresja", "dataset", "trenowanie", "dane", "data science", "bert"
            ],
            "travel": [
                "podrÃ³Å¼", "hotel", "lot", "bilet", "restauracja", "turystyka", "zwiedzanie", 
                "wakacje", "urlop", "wycieczka", "miasto", "wyjazd", "rezerwacja", "atrakcje",
                "lotnisko", "bagaÅ¼", "voucher", "mapa", "paszport", "waluta", "wymiana", "wiza",
                "transport", "warszawa", "krakÃ³w", "wrocÅ‚aw", "gdaÅ„sk", "trip", "travel"
            ],
            "crypto_finance": [
                "bitcoin", "ethereum", "token", "crypto", "kryptowaluta", "blockchain", "defi",
                "solana", "pump", "swap", "chart", "portfel", "wallet", "gieÅ‚da", "exchange",
                "inwestycja", "staking", "yield", "trading", "altcoin", "nft", "tokenizacja",
                "smart contract", "kontrakt", "rugpull", "kapitalizacja", "btc", "eth"
            ],
            "writing_content": [
                "napisz", "artykuÅ‚", "post", "blog", "esej", "opis", "ogÅ‚oszenie", "aukcja",
                "recenzja", "podsumowanie", "tekst", "headline", "tytuÅ‚", "format", "styl",
                "seo", "copywriting", "content", "treÅ›Ä‡", "publikacja", "hashtag", "social media",
                "newsletter", "mail", "email", "podpis", "nagÅ‚Ã³wek", "biografia", "portfolio"
            ],
            "creative": [
                "pomysÅ‚", "kreatywny", "oryginalny", "twÃ³rczy", "inspiracja", "design", "projekt",
                "sztuka", "grafika", "muzyka", "film", "wideo", "animacja", "logo", "branding",
                "ilustracja", "fotografia", "rysunek", "malarstwo", "obraz", "kompozycja", 
                "kreacja", "wyobraÅº", "namaluj", "narysuj", "zaprojektuj", "edytuj"
            ],
            "business": [
                "biznes", "firma", "spÃ³Å‚ka", "startup", "przedsiÄ™biorstwo", "produkt", "usÅ‚uga",
                "marketing", "sprzedaÅ¼", "rynek", "klient", "konkurencja", "strategia", "analiza",
                "rozwÃ³j", "wzrost", "przychÃ³d", "zysk", "rentownoÅ›Ä‡", "roi", "kpi", "model biznesowy",
                "pitch", "inwestor", "finansowanie", "budÅ¼et", "koszt", "zarzÄ…dzanie", "zespÃ³Å‚"
            ],
            "personal": [
                "ja", "ty", "my", "mÃ³j", "twÃ³j", "nasz", "mnie", "tobie", "nas", "osobisty",
                "prywatny", "relacja", "zwiÄ…zek", "rodzina", "przyjaciel", "emocje", "uczucia",
                "problem", "pomoc", "rada", "pytanie", "odpowiedÅº", "opinia", "feedback", "zdanie",
                "myÅ›lÄ™", "czujÄ™", "uwaÅ¼am", "wierzÄ™", "chcÄ™", "potrzebujÄ™", "lubiÄ™", "podoba"
            ]
        }
        
        # Dodaj tematy z CONTEXT_DICTIONARIES
        for context_type, categories in CONTEXT_DICTIONARIES.items():
            if context_type not in topics:
                topics[context_type] = []
            for category, keywords in categories.items():
                topics[context_type].extend(keywords)
        
        return topics
    
    def _initialize_intent_patterns(self) -> Dict[str, List[str]]:
        """Inicjalizuje wzorce dla intencji"""
        return {
            "question": [
                r"^(co|jak|dlaczego|kiedy|gdzie|czy|kto)\s",
                r"\?$",
                r"powiedz mi",
                r"wyjaÅ›nij",
                r"wytÅ‚umacz",
                r"odpowiedz",
                r"ktÃ³re",
                r"ile",
                r"w jaki sposÃ³b"
            ],
            "request": [
                r"^(zrÃ³b|napisz|stwÃ³rz|wygeneruj|oblicz|przeanalizuj)",
                r"proszÄ™ (o|ciÄ™|ciebie)",
                r"moÅ¼esz (proszÄ™|)",
                r"chciaÅ‚(a)?bym",
                r"potrzebujÄ™",
                r"pomÃ³Å¼ mi",
                r"chcÄ™ (Å¼ebyÅ›|abyÅ›)"
            ],
            "feedback": [
                r"(Å›wietnie|dobrze|Åºle|kiepsko|nie|tak|zgadzam|nie zgadzam)",
                r"to (jest|byÅ‚o) (Å›wietne|dobre|zÅ‚e|kiepskie|niewÅ‚aÅ›ciwe)",
                r"podoba mi siÄ™",
                r"nie podoba mi siÄ™",
                r"nie rozumiem",
                r"to nie to",
                r"dokÅ‚adnie",
                r"wÅ‚aÅ›nie"
            ],
            "greeting": [
                r"^(czeÅ›Ä‡|hej|witaj|dzieÅ„ dobry|dobry wieczÃ³r|siema|siemka|hello)",
                r"jak siÄ™ masz",
                r"co sÅ‚ychaÄ‡",
                r"miÅ‚o ciÄ™ (widzieÄ‡|spotkaÄ‡)",
                r"^hej"
            ],
            "closing": [
                r"(do widzenia|do zobaczenia|pa pa|papa|czeÅ›Ä‡|na razie|dobranoc)",
                r"(dziÄ™kujÄ™|dziÄ™ki) .{0,20}$",
                r"muszÄ™ (iÅ›Ä‡|koÅ„czyÄ‡|lecieÄ‡)",
                r"to wszystko",
                r"na dziÅ› koniec"
            ],
            "follow_up": [
                r"^(a |oraz |rÃ³wnieÅ¼ |ponadto |dodatkowo |jeszcze |teÅ¼ |takÅ¼e |przy okazji)",
                r"^jeszcze jedno",
                r"^co wiÄ™cej",
                r"^a co (z|jeÅ›li)",
                r"^a jak",
                r"^co jeszcze"
            ]
        }
        
    def analyze_message(self, user_id: str, message: str) -> Dict[str, Any]:
        """
        Analizuje wiadomoÅ›Ä‡ i kontekst
        
        Args:
            user_id: ID uÅ¼ytkownika
            message: TreÅ›Ä‡ wiadomoÅ›ci
            
        Returns:
            SÅ‚ownik wynikÃ³w analizy
        """
        if not message.strip():
            return {
                "main_topic": None,
                "topics": [],
                "main_intent": None,
                "intents": [],
                "is_focused": self.is_focused_conversation,
                "is_casual": self.is_casual_conversation
            }
        
        # ZwiÄ™ksz licznik wiadomoÅ›ci
        self.message_count += 1
        
        # Analizuj tematy
        topics = self._detect_topics(message)
        main_topic = None
        if topics:
            main_topic = topics[0][0]
            self.topic_frequency.update([main_topic])
            self.session_topics.add(main_topic)
            self.recent_topics.append((time.time(), main_topic, topics[0][1]))
        
        # Analizuj intencje
        intents = self._detect_intents(message)
        main_intent = None
        if intents:
            main_intent = intents[0][0]
            self.intent_frequency.update([main_intent])
            self.session_intents.add(main_intent)
            self.recent_intents.append((time.time(), main_intent, intents[0][1]))
        
        # Aktualizuj flagi
        self._update_conversation_state(message, main_topic, main_intent)
        
        # Przygotuj wynik
        result = {
            "main_topic": main_topic,
            "topics": [(t, round(s, 3)) for t, s in topics],
            "main_intent": main_intent,
            "intents": [(i, round(c, 3)) for i, c in intents],
            "is_focused": self.is_focused_conversation,
            "is_casual": self.is_casual_conversation,
            "message_count": self.message_count
        }
        
        return result
    
    def _detect_topics(self, text: str) -> List[Tuple[str, float]]:
        """
        Wykrywa tematy w tekÅ›cie
        
        Args:
            text: Tekst do analizy
            
        Returns:
            Lista krotek (temat, wynik)
        """
        text_lower = text.lower()
        scores = {}
        
        # Policz wystÄ™powanie sÅ‚Ã³w kluczowych dla kaÅ¼dego tematu
        for topic, keywords in self.topic_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    # Daj wyÅ¼szy wynik dla dokÅ‚adnych dopasowaÅ„ caÅ‚ych sÅ‚Ã³w
                    if re.search(r'\b' + re.escape(keyword.lower()) + r'\b', text_lower):
                        score += 1.0
                    else:
                        score += 0.5
            
            # Normalizuj wynik wzglÄ™dem liczby sÅ‚Ã³w kluczowych
            norm_score = score / max(10, len(keywords))
            if norm_score > self.topic_threshold:
                scores[topic] = norm_score
        
        # Sortuj wedÅ‚ug wyniku
        sorted_topics = sorted(scores.items(), key=lambda x: x[1], reverse=True)
        return sorted_topics
    
    def _detect_intents(self, text: str) -> List[Tuple[str, float]]:
        """
        Wykrywa intencje w tekÅ›cie
        
        Args:
            text: Tekst do analizy
            
        Returns:
            Lista krotek (intencja, pewnoÅ›Ä‡)
        """
        text_lower = text.lower()
        confidences = {}
        
        # SprawdÅº wzorce dla kaÅ¼dej intencji
        for intent, patterns in self.intent_patterns.items():
            confidence = 0
            for pattern in patterns:
                if re.search(pattern, text_lower):
                    confidence += 0.3
            
            if confidence > self.intent_threshold:
                confidences[intent] = min(1.0, confidence)
        
        # Dodatkowe reguÅ‚y
        # JeÅ›li wiadomoÅ›Ä‡ jest krÃ³tka i koÅ„czy siÄ™ znakiem zapytania
        if len(text) < 50 and text.strip().endswith("?"):
            confidences["question"] = max(confidences.get("question", 0), 0.8)
        
        # JeÅ›li wiadomoÅ›Ä‡ zaczyna siÄ™ od czasownika w trybie rozkazujÄ…cym
        if re.match(r"^[A-Z].*[^?]$", text) and any(text_lower.startswith(v) for v in ["zrÃ³b", "dodaj", "znajdÅº", "pokaÅ¼", "oblicz"]):
            confidences["request"] = max(confidences.get("request", 0), 0.7)
        
        # Sortuj wedÅ‚ug pewnoÅ›ci
        sorted_intents = sorted(confidences.items(), key=lambda x: x[1], reverse=True)
        return sorted_intents
    
    def _update_conversation_state(self, message: str, main_topic: Optional[str], main_intent: Optional[str]) -> None:
        """
        Aktualizuje stan konwersacji
        
        Args:
            message: WiadomoÅ›Ä‡
            main_topic: GÅ‚Ã³wny temat
            main_intent: GÅ‚Ã³wna intencja
        """
        # SprawdÅº, czy konwersacja jest skoncentrowana
        if len(self.recent_topics) >= 3:
            topics = [t[1] for t in self.recent_topics[-3:]]
            if len(set(topics)) <= 2:  # Maks 2 rÃ³Å¼ne tematy w ostatnich 3 wiadomoÅ›ciach
                self.is_focused_conversation = True
            else:
                self.is_focused_conversation = False
        
        # SprawdÅº, czy konwersacja jest nieformalna
        if main_intent == "greeting" or main_intent == "closing":
            self.is_casual_conversation = True
        
        if len(message) < 15 or message.count(" ") < 3:
            self.is_casual_conversation = True
        
        # JeÅ›li temat jest biznesowy lub techniczny, to nie jest casual
        if main_topic in ["programming", "ai_ml", "business", "crypto_finance"]:
            self.is_casual_conversation = False
        
        # JeÅ›li temat jest osobisty, to prawdopodobnie casual
        if main_topic == "personal":
            self.is_casual_conversation = True
    
    def get_conversation_summary(self) -> Dict[str, Any]:
        """
        Zwraca podsumowanie konwersacji
        
        Returns:
            SÅ‚ownik z podsumowaniem
        """
        # NajczÄ™stszy temat
        most_common_topic = self.topic_frequency.most_common(1)
        top_topic = most_common_topic[0][0] if most_common_topic else None
        
        # NajczÄ™stsza intencja
        most_common_intent = self.intent_frequency.most_common(1)
        top_intent = most_common_intent[0][0] if most_common_intent else None
        
        # Oblicz zÅ‚oÅ¼onoÅ›Ä‡ konwersacji (ile rÃ³Å¼nych tematÃ³w i intencji)
        topic_complexity = len(self.session_topics)
        intent_complexity = len(self.session_intents)
        
        # Czas trwania sesji
        session_duration = time.time() - self.session_start
        
        return {
            "dominant_topic": top_topic,
            "dominant_intent": top_intent,
            "topic_complexity": topic_complexity,
            "intent_complexity": intent_complexity,
            "message_count": self.message_count,
            "session_duration_seconds": int(session_duration),
            "is_focused": self.is_focused_conversation,
            "is_casual": self.is_casual_conversation
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GENERATOR SUGESTII
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ProactiveSuggestionGenerator:
    """Generator proaktywnych sugestii bazujÄ…cy na kontekÅ›cie, psychice i uÅ¼ytkowniku"""
    
    def __init__(self):
        """Inicjalizuje generator"""
        # Komponenty
        self.conversation_analyzer = ConversationAnalyzer()
        
        # Konfiguracja
        self.suggestion_threshold = 0.6  # PrÃ³g dla wyÅ›wietlenia sugestii
        self.suggestion_cooldown = 300  # Minimalna przerwa miÄ™dzy sugestiami (sekundy)
        self.max_suggestions = 3  # Maksymalna liczba sugestii
        
        # PamiÄ™Ä‡ sugestii
        self.recent_suggestions = deque(maxlen=20)  # (timestamp, suggestion, context)
        self.last_suggestion_time = 0
        
        # Baza wiedzy o sugestiach
        self.suggestion_templates = self._initialize_suggestion_templates()
        self.situational_triggers = self._initialize_situational_triggers()
        
        # Statystyki
        self.suggestion_stats = {
            "generated": 0,
            "by_topic": defaultdict(int),
            "by_intent": defaultdict(int)
        }
        
    def _initialize_suggestion_templates(self) -> Dict[str, List[Dict[str, Any]]]:
        """Inicjalizuje szablony sugestii dla rÃ³Å¼nych tematÃ³w"""
        return {
            "programming": [
                {
                    "text": "ðŸ’¡ MogÄ™ przeanalizowaÄ‡ ten bÅ‚Ä…d i zaproponowaÄ‡ rozwiÄ…zanie",
                    "conditions": {"intent": "question", "keywords": ["bÅ‚Ä…d", "error", "bug", "nie dziaÅ‚a"]},
                    "priority": 0.9
                },
                {
                    "text": "ðŸ’¡ Chcesz, Å¼ebym zoptymalizowaÅ‚ ten kod pod kÄ…tem wydajnoÅ›ci?",
                    "conditions": {"keywords": ["kod", "funkcja", "powolny", "optymalizacja"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ MogÄ™ dodaÄ‡ testy jednostkowe do tego kodu",
                    "conditions": {"keywords": ["test", "testowanie", "unittest", "pytest"]},
                    "priority": 0.7
                },
                {
                    "text": "ðŸ’¡ MogÄ™ zrefaktoryzowaÄ‡ ten kod, aby byÅ‚ bardziej czytelny",
                    "conditions": {"keywords": ["refaktor", "czytelnoÅ›Ä‡", "czysty kod", "clean"]},
                    "priority": 0.7
                },
                {
                    "text": "ðŸ’¡ Potrzebujesz pomocy z integracjÄ… Git/GitHub?",
                    "conditions": {"keywords": ["git", "github", "commit", "merge", "branch"]},
                    "priority": 0.7
                }
            ],
            "ai_ml": [
                {
                    "text": "ðŸ’¡ MogÄ™ zaprojektowaÄ‡ prompt inÅ¼ynieryjny dla tego przypadku",
                    "conditions": {"keywords": ["prompt", "gpt", "llm", "chatgpt"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ Chcesz przeanalizowaÄ‡ architekturÄ™ tego modelu AI?",
                    "conditions": {"keywords": ["model", "architektura", "neural", "sieÄ‡"]},
                    "priority": 0.7
                },
                {
                    "text": "ðŸ’¡ MogÄ™ pomÃ³c w przygotowaniu danych do treningu modelu",
                    "conditions": {"keywords": ["dane", "dataset", "trenowanie", "uczenie"]},
                    "priority": 0.7
                }
            ],
            "travel": [
                {
                    "text": "ðŸ’¡ MogÄ™ znaleÅºÄ‡ najlepsze hotele w tej lokalizacji",
                    "conditions": {"keywords": ["hotel", "nocleg", "gdzie spaÄ‡"]},
                    "priority": 0.9
                },
                {
                    "text": "ðŸ’¡ Chcesz zobaczyÄ‡ popularne restauracje w okolicy?",
                    "conditions": {"keywords": ["restauracja", "jedzenie", "gdzie zjeÅ›Ä‡", "knajpa"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ MogÄ™ zaplanowaÄ‡ trasÄ™ zwiedzania na 1-3 dni",
                    "conditions": {"intent": "request", "keywords": ["zwiedzanie", "atrakcje", "zabytki", "plan"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ Potrzebujesz sprawdziÄ‡ pogodÄ™ dla tego miejsca?",
                    "conditions": {"keywords": ["pogoda", "temperatura", "klimat"]},
                    "priority": 0.7
                }
            ],
            "crypto_finance": [
                {
                    "text": "ðŸ’¡ MogÄ™ przeanalizowaÄ‡ potencjalne ryzyko tego tokena",
                    "conditions": {"keywords": ["token", "crypto", "ryzyko", "rugpull"]},
                    "priority": 0.9
                },
                {
                    "text": "ðŸ’¡ Chcesz porÃ³wnaÄ‡ ten projekt z podobnymi?",
                    "conditions": {"keywords": ["projekt", "porÃ³wnanie", "podobne", "alternatywa"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ MogÄ™ sprawdziÄ‡ aktualne statystyki on-chain",
                    "conditions": {"keywords": ["on-chain", "statystyki", "transakcje", "wolumen"]},
                    "priority": 0.8
                }
            ],
            "writing_content": [
                {
                    "text": "ðŸ’¡ MogÄ™ napisaÄ‡ alternatywnÄ… wersjÄ™ w innym stylu",
                    "conditions": {"keywords": ["napisz", "tekst", "styl", "wersja"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ Chcesz dodaÄ‡ angielskÄ… wersjÄ™ tego tekstu?",
                    "conditions": {"keywords": ["tÅ‚umaczenie", "po angielsku", "wersja", "jÄ™zyk"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ MogÄ™ zoptymalizowaÄ‡ ten tekst pod kÄ…tem SEO",
                    "conditions": {"keywords": ["seo", "pozycjonowanie", "google", "keywords"]},
                    "priority": 0.7
                },
                {
                    "text": "ðŸ’¡ Potrzebujesz skrÃ³conej wersji tego tekstu?",
                    "conditions": {"keywords": ["skrÃ³ciÄ‡", "podsumowanie", "krÃ³tszy", "streszczenie"]},
                    "priority": 0.7
                }
            ],
            "creative": [
                {
                    "text": "ðŸ’¡ MogÄ™ wygenerowaÄ‡ wiÄ™cej wariantÃ³w tego pomysÅ‚u",
                    "conditions": {"keywords": ["pomysÅ‚", "wariant", "wersja", "opcja"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ Chcesz, Å¼ebym rozwinÄ…Å‚ ten koncept bardziej szczegÃ³Å‚owo?",
                    "conditions": {"keywords": ["koncept", "rozwinÄ…Ä‡", "szczegÃ³Å‚y", "rozwiniÄ™cie"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ MogÄ™ zaproponowaÄ‡ kreatywne rozwiÄ…zanie tego problemu",
                    "conditions": {"keywords": ["problem", "rozwiÄ…zanie", "kreatywny", "pomysÅ‚"]},
                    "priority": 0.7
                }
            ],
            "business": [
                {
                    "text": "ðŸ’¡ MogÄ™ przygotowaÄ‡ analizÄ™ SWOT dla tego pomysÅ‚u",
                    "conditions": {"keywords": ["analiza", "swot", "biznes", "firma"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ Chcesz zobaczyÄ‡ przykÅ‚adowy model biznesowy?",
                    "conditions": {"keywords": ["model biznesowy", "przychody", "koszty", "monetyzacja"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ MogÄ™ stworzyÄ‡ szkic pitch decku dla tego pomysÅ‚u",
                    "conditions": {"keywords": ["pitch", "prezentacja", "inwestor", "startup"]},
                    "priority": 0.7
                }
            ],
            "personal": [
                {
                    "text": "ðŸ’¡ JeÅ›li potrzebujesz szczegÃ³Å‚owej porady w tej kwestii, powiedz wiÄ™cej",
                    "conditions": {"intent": "question", "keywords": ["rada", "porada", "problem", "pomÃ³Å¼"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ Chcesz, Å¼ebym rozwaÅ¼yÅ‚ to z innej perspektywy?",
                    "conditions": {"keywords": ["perspektywa", "punkt widzenia", "inaczej", "alternatywa"]},
                    "priority": 0.8
                },
                {
                    "text": "ðŸ’¡ MogÄ™ pomÃ³c podjÄ…Ä‡ decyzjÄ™ metodÄ… za i przeciw",
                    "conditions": {"keywords": ["decyzja", "wybÃ³r", "za i przeciw", "nie wiem co"]},
                    "priority": 0.7
                }
            ],
            "general": [
                {
                    "text": "ðŸ’¡ Czy mogÄ™ pomÃ³c w czymÅ› jeszcze?",
                    "conditions": {"intent": "closing"},
                    "priority": 0.6
                },
                {
                    "text": "ðŸ’¡ Masz jakieÅ› pytania dotyczÄ…ce mojej odpowiedzi?",
                    "conditions": {"no_response_time": 60},
                    "priority": 0.5
                },
                {
                    "text": "ðŸ’¡ MoÅ¼e ciÄ™ zainteresowaÄ‡ powiÄ…zany temat...",
                    "conditions": {"contextual_memory_available": True},
                    "priority": 0.7
                }
            ]
        }
        
    def _initialize_situational_triggers(self) -> List[Dict[str, Any]]:
        """Inicjalizuje wyzwalacze sytuacyjne dla sugestii"""
        return [
            {
                "name": "long_conversation",
                "conditions": {"message_count": 20},
                "suggestion": "ðŸ’¡ DÅ‚uga rozmowa! MogÄ™ zrobiÄ‡ podsumowanie kluczowych punktÃ³w.",
                "priority": 0.7
            },
            {
                "name": "repeated_question",
                "conditions": {"repeated_intent": "question", "count": 3},
                "suggestion": "ðŸ’¡ WidzÄ™, Å¼e masz wiele pytaÅ„. MoÅ¼e pomogÄ™ ci znaleÅºÄ‡ bardziej kompleksowe ÅºrÃ³dÅ‚o informacji?",
                "priority": 0.7
            },
            {
                "name": "frustrated_user",
                "conditions": {"emotional_valence": "<0.3", "messages": 3},
                "suggestion": "ðŸ’¡ WyglÄ…da na to, Å¼e mogÄ™ lepiej pomÃ³c. MoÅ¼e sprÃ³bujmy innego podejÅ›cia?",
                "priority": 0.9
            },
            {
                "name": "technical_to_casual",
                "conditions": {"topic_shift": ["programming", "personal"]},
                "suggestion": "ðŸ’¡ Chcesz na chwilÄ™ odejÅ›Ä‡ od tematÃ³w technicznych? Jestem otwarty na rozmowÄ™ o wszystkim.",
                "priority": 0.7
            },
            {
                "name": "research_opportunity",
                "conditions": {"intent": "question", "no_ltm_match": True},
                "suggestion": "ðŸ’¡ To interesujÄ…ce pytanie! Chcesz, Å¼ebym poszukaÅ‚ wiÄ™cej informacji na ten temat?",
                "priority": 0.8
            }
        ]
    
    async def generate_suggestions(
        self, 
        user_id: str, 
        message: str, 
        conversation_history: List[Dict[str, Any]],
        last_ai_response: str = "",
        force_suggestion: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Generuje proaktywne sugestie na podstawie kontekstu, stanu psychicznego i historii
        
        Args:
            user_id: ID uÅ¼ytkownika
            message: WiadomoÅ›Ä‡ uÅ¼ytkownika
            conversation_history: Historia konwersacji
            last_ai_response: Ostatnia odpowiedÅº AI
            force_suggestion: WymuÅ› sugestiÄ™ nawet jeÅ›li cooldown nie minÄ…Å‚
            
        Returns:
            Lista sugestii w formacie [{text, score, context}]
        """
        # SprawdÅº cooldown
        current_time = time.time()
        if not force_suggestion and (current_time - self.last_suggestion_time) < self.suggestion_cooldown:
            return []
        
        # Analizuj wiadomoÅ›Ä‡
        analysis = self.conversation_analyzer.analyze_message(user_id, message)
        main_topic = analysis.get("main_topic")
        main_intent = analysis.get("main_intent")
        
        # Pobierz stan psychiczny
        psyche_state = get_psyche_state()
        
        # Analizuj emocjonalnie wiadomoÅ›Ä‡ uÅ¼ytkownika
        emotional_analysis = process_user_message(message, user_id)
        
        # Wybierz odpowiednie szablony na podstawie tematu i intencji
        candidate_suggestions = []
        
        # 1. Szablony z gÅ‚Ã³wnego tematu
        if main_topic and main_topic in self.suggestion_templates:
            topic_templates = self.suggestion_templates[main_topic]
            candidate_suggestions.extend(self._evaluate_templates(
                topic_templates, 
                message, 
                main_intent,
                emotional_analysis
            ))
        
        # 2. Zawsze sprawdÅº szablony ogÃ³lne
        general_templates = self.suggestion_templates.get("general", [])
        candidate_suggestions.extend(self._evaluate_templates(
            general_templates, 
            message, 
            main_intent,
            emotional_analysis
        ))
        
        # 3. SprawdÅº wyzwalacze sytuacyjne
        situational_suggestions = self._check_situational_triggers(
            user_id, message, conversation_history, 
            analysis, psyche_state, emotional_analysis
        )
        candidate_suggestions.extend(situational_suggestions)
        
        # 4. SprawdÅº pamiÄ™Ä‡ LTM dla kontekstowych sugestii
        contextual_suggestions = await self._generate_contextual_suggestions(
            user_id, message, main_topic
        )
        candidate_suggestions.extend(contextual_suggestions)
        
        # UsuÅ„ duplikaty i sortuj wedÅ‚ug score
        unique_suggestions = {}
        for sugg in candidate_suggestions:
            if sugg["text"] not in unique_suggestions or unique_suggestions[sugg["text"]]["score"] < sugg["score"]:
                unique_suggestions[sugg["text"]] = sugg
        
        # Sortuj wedÅ‚ug score
        sorted_suggestions = sorted(unique_suggestions.values(), key=lambda x: x["score"], reverse=True)
        
        # Filtruj sugestie, ktÃ³re niedawno byÅ‚y pokazywane
        recent_texts = [s[1] for s in self.recent_suggestions]
        filtered_suggestions = [
            s for s in sorted_suggestions 
            if s["text"] not in recent_texts or force_suggestion
        ]
        
        # JeÅ›li znaleziono sugestie, zaktualizuj czas ostatniej sugestii
        if filtered_suggestions:
            self.last_suggestion_time = current_time
            
            # Zapisz sugestie do historii
            for sugg in filtered_suggestions[:self.max_suggestions]:
                self.recent_suggestions.append((current_time, sugg["text"], sugg["context"]))
                self.suggestion_stats["generated"] += 1
                if main_topic:
                    self.suggestion_stats["by_topic"][main_topic] += 1
                if main_intent:
                    self.suggestion_stats["by_intent"][main_intent] += 1
        
        return filtered_suggestions[:self.max_suggestions]
    
    def _evaluate_templates(
        self, 
        templates: List[Dict[str, Any]], 
        message: str, 
        intent: Optional[str],
        emotional_analysis: Dict[str, Any]
    ) -> List[Dict[str, float]]:
        """
        Ocenia szablony sugestii pod kÄ…tem dopasowania
        
        Args:
            templates: Lista szablonÃ³w
            message: WiadomoÅ›Ä‡ uÅ¼ytkownika
            intent: Intencja uÅ¼ytkownika
            emotional_analysis: Analiza emocjonalna
        
        Returns:
            Lista pasujÄ…cych sugestii z wynikami
        """
        message_lower = message.lower()
        matching_suggestions = []
        
        for template in templates:
            score = template.get("priority", 0.5)
            conditions = template.get("conditions", {})
            
            # SprawdÅº warunki
            # 1. ZgodnoÅ›Ä‡ intencji
            if "intent" in conditions and conditions["intent"] != intent:
                continue
            
            # 2. ObecnoÅ›Ä‡ sÅ‚Ã³w kluczowych
            if "keywords" in conditions:
                keywords_found = sum(1 for kw in conditions["keywords"] if kw.lower() in message_lower)
                if keywords_found == 0:
                    continue
                score += 0.1 * min(keywords_found, 3)  # Max +0.3 za sÅ‚owa kluczowe
            
            # 3. Dostosowanie emocjonalne
            if emotional_analysis and "valence" in emotional_analysis:
                if emotional_analysis["valence"] < 0 and "negative_emotion" in conditions:
                    score += 0.2
                elif emotional_analysis["valence"] > 0 and "positive_emotion" in conditions:
                    score += 0.2
            
            # JeÅ›li przeszedÅ‚ warunki, dodaj do pasujÄ…cych
            if score >= self.suggestion_threshold:
                matching_suggestions.append({
                    "text": template["text"],
                    "score": score,
                    "context": {
                        "template_type": "standard",
                        "conditions_met": list(conditions.keys())
                    }
                })
        
        return matching_suggestions
    
    def _check_situational_triggers(
        self,
        user_id: str,
        message: str,
        conversation_history: List[Dict[str, Any]],
        analysis: Dict[str, Any],
        psyche_state: Dict[str, Any],
        emotional_analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        Sprawdza wyzwalacze sytuacyjne
        
        Args:
            user_id: ID uÅ¼ytkownika
            message: WiadomoÅ›Ä‡ uÅ¼ytkownika
            conversation_history: Historia konwersacji
            analysis: Analiza bieÅ¼Ä…cej wiadomoÅ›ci
            psyche_state: Stan psychiczny AI
            emotional_analysis: Analiza emocjonalna
            
        Returns:
            Lista sugestii sytuacyjnych
        """
        triggered_suggestions = []
        
        # SprawdÅº kaÅ¼dy wyzwalacz
        for trigger in self.situational_triggers:
            trigger_conditions = trigger.get("conditions", {})
            trigger_score = trigger.get("priority", 0.5)
            conditions_met = True
            
            # SprawdÅº warunki
            for cond_name, cond_value in trigger_conditions.items():
                # Liczba wiadomoÅ›ci
                if cond_name == "message_count":
                    if analysis.get("message_count", 0) < cond_value:
                        conditions_met = False
                        break
                
                # PowtarzajÄ…ca siÄ™ intencja
                if cond_name == "repeated_intent":
                    intent_value = trigger_conditions.get("repeated_intent")
                    count_value = trigger_conditions.get("count", 2)
                    
                    intent_count = sum(1 for msg in conversation_history[-5:] 
                                     if msg.get("role") == "user" and "intent" in msg and msg["intent"] == intent_value)
                    
                    if intent_count < count_value:
                        conditions_met = False
                        break
                
                # Stan emocjonalny
                if cond_name == "emotional_valence":
                    if "<" in cond_value:
                        threshold = float(cond_value.replace("<", ""))
                        if not emotional_analysis or emotional_analysis.get("valence", 0.5) >= threshold:
                            conditions_met = False
                            break
                    elif ">" in cond_value:
                        threshold = float(cond_value.replace(">", ""))
                        if not emotional_analysis or emotional_analysis.get("valence", 0.5) <= threshold:
                            conditions_met = False
                            break
                
                # Zmiana tematu
                if cond_name == "topic_shift":
                    from_topic, to_topic = cond_value
                    if len(conversation_history) < 3:
                        conditions_met = False
                        break
                    
                    previous_topics = [msg.get("topic") for msg in conversation_history[-3:] 
                                     if msg.get("role") == "user" and "topic" in msg]
                    
                    if from_topic not in previous_topics or analysis.get("main_topic") != to_topic:
                        conditions_met = False
                        break
                
                # Brak dopasowaÅ„ LTM
                if cond_name == "no_ltm_match" and cond_value is True:
                    # To bÄ™dzie sprawdzane w osobnej funkcji _generate_contextual_suggestions
                    pass
            
            # JeÅ›li wszystkie warunki speÅ‚nione, dodaj sugestiÄ™
            if conditions_met:
                triggered_suggestions.append({
                    "text": trigger["suggestion"],
                    "score": trigger_score,
                    "context": {
                        "template_type": "situational",
                        "trigger_name": trigger["name"]
                    }
                })
        
        return triggered_suggestions
    
    async def _generate_contextual_suggestions(
        self,
        user_id: str,
        message: str,
        topic: Optional[str]
    ) -> List[Dict[str, Any]]:
        """
        Generuje sugestie na podstawie kontekstu i pamiÄ™ci LTM
        
        Args:
            user_id: ID uÅ¼ytkownika
            message: WiadomoÅ›Ä‡ uÅ¼ytkownika
            topic: GÅ‚Ã³wny temat
            
        Returns:
            Lista sugestii kontekstowych
        """
        # Pobierz powiÄ…zane fakty z LTM
        ltm_results = await asyncio.to_thread(ltm_search_hybrid, message, limit=3)
        
        # JeÅ›li nie znaleziono powiÄ…zanych faktÃ³w, zaproponuj naukÄ™
        if not ltm_results:
            if any(q in message.lower() for q in ["co to", "czym jest", "jak dziaÅ‚a", "wyjaÅ›nij"]):
                return [{
                    "text": "ðŸ’¡ MogÄ™ poszukaÄ‡ wiÄ™cej informacji na ten temat w internecie",
                    "score": 0.85,
                    "context": {
                        "template_type": "contextual",
                        "trigger": "no_ltm_match"
                    }
                }]
            return []
        
        # JeÅ›li znaleziono powiÄ…zane fakty, zaproponuj gÅ‚Ä™bsze wejÅ›cie w temat
        if len(ltm_results) >= 2:
            related_text = ltm_results[1].get("text", "")
            if len(related_text) > 20:
                # WydobÄ…dÅº temat z powiÄ…zanego faktu
                related_topic = self._extract_topic_from_text(related_text)
                if related_topic and related_topic != topic:
                    return [{
                        "text": f"ðŸ’¡ MoÅ¼e zainteresuje ciÄ™ teÅ¼ powiÄ…zany temat: {related_topic}",
                        "score": 0.75,
                        "context": {
                            "template_type": "contextual",
                            "trigger": "related_topic"
                        }
                    }]
        
        return []
    
    def _extract_topic_from_text(self, text: str) -> Optional[str]:
        """
        Wydobywa temat z tekstu
        
        Args:
            text: Tekst do analizy
            
        Returns:
            Wydobyty temat lub None
        """
        # Proste podejÅ›cie - poszukaj rzeczownikÃ³w na poczÄ…tku tekstu
        first_sentence = text.split(".")[0].strip()
        
        # Poszukaj pierwszego istotnego rzeczownika
        important_nouns = ["technologia", "metoda", "system", "framework", "jÄ™zyk", "algorytm", 
                          "platforma", "protokÃ³Å‚", "narzÄ™dzie", "biblioteka", "koncept", "teoria"]
        
        for noun in important_nouns:
            if noun in first_sentence.lower():
                # ZwrÃ³Ä‡ fragment tekstu zawierajÄ…cy ten rzeczownik
                start_idx = first_sentence.lower().find(noun)
                end_idx = start_idx + 30
                fragment = first_sentence[start_idx:min(end_idx, len(first_sentence))]
                # JeÅ›li fragment koÅ„czy siÄ™ w Å›rodku zdania, znajdÅº ostatni koniec sÅ‚owa
                if end_idx < len(first_sentence):
                    last_space = fragment.rfind(" ")
                    if last_space > 0:
                        fragment = fragment[:last_space]
                return fragment
        
        # JeÅ›li nie znaleziono konkretnego rzeczownika, zwrÃ³Ä‡ pierwsze 3-5 sÅ‚Ã³w
        words = first_sentence.split()
        if len(words) >= 3:
            return " ".join(words[:min(5, len(words))])
        
        return None
    
    def inject_suggestion_to_prompt(self, base_prompt: str, suggestions: List[Dict[str, Any]]) -> str:
        """
        Dodaje sugestie do promptu systemowego
        
        Args:
            base_prompt: Bazowy prompt systemowy
            suggestions: Lista sugestii
            
        Returns:
            Prompt z dodanymi sugestiami
        """
        if not suggestions:
            return base_prompt
        
        # Wybierz najlepszÄ… sugestiÄ™
        best_suggestion = suggestions[0]["text"]
        
        enhanced_prompt = f"""{base_prompt}

ðŸŽ¯ PROAKTYWNA POMOC:
Na koÅ„cu odpowiedzi (po pustej linii) dodaj tÄ™ sugestiÄ™:
{best_suggestion}

Format: naturalny, konwersacyjny, jakbyÅ› z wÅ‚asnej inicjatywy chciaÅ‚ pomÃ³c."""
        
        return enhanced_prompt
    
    def get_suggestion_stats(self) -> Dict[str, Any]:
        """
        Zwraca statystyki sugestii
        
        Returns:
            SÅ‚ownik statystyk sugestii
        """
        return {
            "total_generated": self.suggestion_stats["generated"],
            "by_topic": dict(self.suggestion_stats["by_topic"]),
            "by_intent": dict(self.suggestion_stats["by_intent"]),
            "recent_suggestions": list(self.recent_suggestions)
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTERFEJS PUBLICZNY
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Globalna instancja generatora sugestii
suggestion_generator = ProactiveSuggestionGenerator()

async def get_proactive_suggestions(
    user_id: str, 
    message: str, 
    conversation_history: List[Dict[str, Any]] = None,
    last_ai_response: str = "",
    force: bool = False
) -> List[Dict[str, Any]]:
    """
    GÅ‚Ã³wna funkcja do generowania proaktywnych sugestii
    
    Args:
        user_id: ID uÅ¼ytkownika
        message: WiadomoÅ›Ä‡ uÅ¼ytkownika
        conversation_history: Historia konwersacji (opcjonalna)
        last_ai_response: Ostatnia odpowiedÅº AI
        force: WymuÅ› sugestiÄ™ nawet jeÅ›li cooldown nie minÄ…Å‚
        
    Returns:
        Lista sugestii w formacie [{text, score, context}]
    """
    if conversation_history is None:
        conversation_history = []
    
    suggestions = await suggestion_generator.generate_suggestions(
        user_id=user_id,
        message=message,
        conversation_history=conversation_history,
        last_ai_response=last_ai_response,
        force_suggestion=force
    )
    
    return suggestions

def inject_suggestions_to_prompt(base_prompt: str, suggestions: List[Dict[str, Any]]) -> str:
    """
    Dodaje sugestie do promptu systemowego
    
    Args:
        base_prompt: Bazowy prompt systemowy
        suggestions: Lista sugestii z get_proactive_suggestions()
        
    Returns:
        Prompt z dodanymi sugestiami
    """
    return suggestion_generator.inject_suggestion_to_prompt(base_prompt, suggestions)

def get_smart_suggestions(user_message: str, last_ai_response: str = "") -> List[str]:
    """
    Legacy funkcja - zwraca listÄ™ prostych sugestii (kompatybilnoÅ›Ä‡ wsteczna)
    
    Args:
        user_message: WiadomoÅ›Ä‡ uÅ¼ytkownika
        last_ai_response: Ostatnia odpowiedÅº AI
        
    Returns:
        Lista prostych tekstÃ³w sugestii
    """
    msg_lower = user_message.lower()
    suggestions = []
    
    # Kod/programowanie
    if '```' in last_ai_response or 'def ' in last_ai_response:
        suggestions.extend([
            "Uruchom ten kod",
            "WyjaÅ›nij krok po kroku",
            "Dodaj testy"
        ])
    
    # Post/aukcja
    elif len(last_ai_response) > 300 and any(w in msg_lower for w in ['napisz', 'opis', 'post']):
        suggestions.extend([
            "SkrÃ³Ä‡ do 150 sÅ‚Ã³w",
            "ZrÃ³b wersjÄ™ angielskÄ…",
            "Dodaj hashtagi"
        ])
    
    # Token/krypto
    elif any(w in msg_lower for w in ['token', 'coin', 'crypto']):
        suggestions.extend([
            "SprawdÅº aktualnÄ… cenÄ™",
            "Analiza rugpull risk",
            "PokaÅ¼ podobne tokeny"
        ])
    
    # Lokalizacja/travel
    elif any(w in msg_lower for w in ['hotel', 'restauracj', 'miasto']):
        suggestions.extend([
            "PokaÅ¼ na mapie",
            "SprawdÅº opinie",
            "ZnajdÅº podobne"
        ])
    
    # DomyÅ›lne
    if not suggestions:
        suggestions = [
            "Powiedz wiÄ™cej",
            "Podaj przykÅ‚ad", 
            "Alternatywne rozwiÄ…zanie"
        ]
    
    return suggestions[:3]  # Max 3 sugestie

def analyze_context(user_message: str, conversation_history: List[Dict] = None) -> Optional[str]:
    """
    Legacy funkcja - analizuje kontekst (kompatybilnoÅ›Ä‡ wsteczna)
    
    Args:
        user_message: WiadomoÅ›Ä‡ uÅ¼ytkownika
        conversation_history: Historia konwersacji
        
    Returns:
        Sugestia lub None
    """
    msg_lower = user_message.lower()
    
    # Kod/programowanie
    if any(w in msg_lower for w in ['error', 'bÅ‚Ä…d', 'bug', 'nie dziaÅ‚a', 'crashuje', 'traceback']):
        return "ðŸ’¡ WidzÄ™ Å¼e masz problem z kodem. MogÄ™ przeanalizowaÄ‡ bÅ‚Ä…d, zaproponowaÄ‡ fix lub uruchomiÄ‡ debugger."
    
    if any(w in msg_lower for w in ['kod', 'funkcj', 'class', 'def ', 'import ', 'git ']):
        return "ðŸ’¡ Piszesz kod? MogÄ™ ci pomÃ³c z refaktoringiem, testami, dokumentacjÄ… lub code review."
    
    # Travel/lokalizacja
    if any(w in msg_lower for w in ['hotel', 'restauracj', 'lot', 'bilet', 'podrÃ³Å¼', 'warszaw', 'krakÃ³', 'wrocÅ‚aw']):
        return "ðŸ’¡ Planujesz podrÃ³Å¼? MogÄ™ znaleÅºÄ‡ najlepsze hotele, restauracje, atrakcje i sprawdziÄ‡ pogodÄ™."
    
    # Brak konkretnego kontekstu
    if len(user_message) < 10:
        return "ðŸ’¡ Jestem gotowy! MogÄ™ pomÃ³c z kodem, pisaniem, travel, krypto, research - pytaj Å›miaÅ‚o."
    
    return None